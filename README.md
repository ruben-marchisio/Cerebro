# Cerebro

Asistente de desarrollo para escritorio construido con Tauri + React. Ofrece chat con modelos locales (Ollama) y remoto (DeepSeek) con auto detecci√≥n y un modo de respaldo en memoria.

## Desarrollo local

- `pnpm dev`: sirve la app web.
- `pnpm tauri dev`: ejecuta la aplicaci√≥n nativa.
- `pnpm build && pnpm tauri build`: genera los artefactos de producci√≥n.

## Runtime local

1. **Instala Ollama** siguiendo la gu√≠a oficial: <https://ollama.com/download>.
2. **Inicia el servicio** con `ollama serve` (la mayor√≠a de instalaciones lo hacen autom√°ticamente). Verifica el estado con `curl http://127.0.0.1:11434/api/version`.
3. **Descarga un modelo ligero recomendado**: `ollama run mistral`. Este paso lo instala y valida en un solo comando.

## Modelos recomendados

- ‚ö° Fast (`llama3.2:3b-instruct`): ideal cuando necesitas respuestas casi instant√°neas para tareas cortas o debugging r√°pido.
- üéØ Balanced (`qwen2.5:3b-instruct`): equilibrio entre velocidad y calidad para trabajo diario y prompts variados.
- üß© Pensativo (`mistral`): √∫salos en prompts m√°s largos o cuando buscas an√°lisis m√°s detallado aunque tarde un poco m√°s.

Con el servicio activo, la aplicaci√≥n mostrar√° el modo `Local (Ollama)` y podr√° generar respuestas en streaming con el bot√≥n **Detener** funcionando para cortar la petici√≥n.

### ¬øY si Ollama no est√° disponible?

- Configura la variable `DEEPSEEK_API_KEY` para usar el modo `Remoto (DeepSeek)`.
- Sin Ollama ni API key, el chat mostrar√° mensajes gu√≠a del modo `Sin modelo` sin romper la interfaz.

### Troubleshooting

- **Modelo faltante**: si lees `model "<nombre>" not found`, instala uno existente (`ollama run mistral`) o actualiza el nombre en la configuraci√≥n.
- **Servicio ca√≠do o puerto ocupado**: reinicia con `ollama serve` y comprueba que el puerto `11434` no est√© en uso (`lsof -i :11434` en macOS/Linux, `netstat -ano | find "11434"` en Windows).
- **Tiempo de espera agotado**: confirma que tu firewall permita conexiones locales y repite `curl http://127.0.0.1:11434/api/version`.

Cuando el modo local se recupera, la etiqueta vuelve a `Local (Ollama)` autom√°ticamente.
